---
layout: default
---

# Tentative syllabus for 2017

* Introduction: parallel data and opportunities
* Unsupervised learning of lexical alignment
    * Directed models: MLE by EM for categorical distributions
    * Undirected models: MLE by gradient-based optimisation
    * Bayesian inference: Dirichlet priors and collapsed inference
    * Feature-rich parameterisation and feature induction with neural networks
* Unsupervised learning of bitext parsing
    * Bitext parsing by weighted deduction
    * Directed graphical models for bitext parsing
* Statistical machine translation
    * From word to phrases and hierarchical rules
    * Evaluation
    * Fitting linear classifiers (tuning)
    * Latent-variable conditional random fields
* Fully supervised neural models
    * Language modelling without Markov assumptions
    * Conditional language modelling (sequence to sequence) and attention mechanism
* Deep generative models for translation and alignment
    * Variational auto-encoder
* Paraphrasing



