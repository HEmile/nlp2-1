---
layout: post
title:  Project 2 
date:   2017-05-03
author: Wilker
categories: projects
---

[Project 2 description]({{ "/nlp2/resources/project_crf/project2.pdf" | absolute_url }}).

Deadline: May 19 at 23:59 GMT-8.


# Code

* [roadmap](https://github.com/uva-slpl/nlp2/blob/gh-pages/resources/notebooks/LV-CRF-Roadmap.ipynb): a tutorial style description of the project that connects theory and practice; in particular, we connect the concepts discussed in class with actual code; this tutorial uses `libitg` (see below);
* [libitg](https://github.com/uva-slpl/nlp2/blob/gh-pages/resources/notebooks/libitg.py): is our implementation of Earley intersection between epsilon-free unweighted FSA and CFGs, we also provide functions to deal with ITGs and length constraints;
* [notebook on intersection](https://github.com/uva-slpl/nlp2/blob/gh-pages/resources/notebooks/ITG.ipynb): you can use this notebook to understand more about the bits and pieces of the parser, but do not copy code from there, for that use [libitg](https://github.com/uva-slpl/nlp2/blob/gh-pages/resources/notebooks/libitg.py)

# Reading

* Model
    * [Lecture slides]({{ "/nlp2/resources/slides/crf.pdf" | absolute_url }})
    * [LV-CRF for Alignment](http://www.aclweb.org/anthology/P11-1042)
    * [LV-CRF for SMT](http://www.aclweb.org/anthology/P08-1024)
    * [Supervised CRFs](http://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)
    * [LV-CRF](https://www.cics.umass.edu/~mccallum/papers/entropygradient-naacl2007.pdf)
* Synchronous grammars
    * [ITGs](https://www.aclweb.org/anthology/J/J97/J97-3002.pdf)
    * [SCFG tutorial by David Chiang]({{ "/nlp2/resources/papers/ChiangSCFG.pdf" | absolute_url }})
    * [Lecture slides]({{ "/nlp2/resources/slides/itg.pdf" | absolute_url }})
* Bitext parsing
    * [Lecture slides]({{ "/nlp2/resources/slides/bitext-parsing.pdf" | absolute_url }})
    * [Notes on Earley intersection]({{ "/nlp2/resources/papers/Aziz-Earley.pdf" | absolute_url }})
    * [Principles and implementation of deductive parsing](https://arxiv.org/abs/cmp-lg/9404008)
    * [Cascade of parsers](http://www.aclweb.org/anthology/N10-1033)
* Hypergraphs
    * [Directed hypergraphs]({{ "/nlp2/resources/papers/GalloEtAl.pdf" | absolute_url }})
    * [Parsing and hypergraphs](https://nlp.stanford.edu/manning/papers/klein_and_manning-parsing_and_hypergraphs-IWPT_2001.pdf)
* FSAs
    * [Knight and May's chapter on applications of weighted automata to NLP]({{ "/nlp2/resources/papers/KnightAndMay.pdf" | absolute_url }})
    * [FSTs in language and speech processing](http://www.cs.nyu.edu/~mohri/pub/cl1.pdf)
    * [Mohri's chapter on weighted automata algorithms]({{ "/nlp2/resources/papers/MohriWAA.pdf" | absolute_url }})
* Semirings 
    * [Goodman's semiring parsing artcile](http://www.aclweb.org/anthology/J/J99/J99-4004.pdf) 
    * [Expectation semiring for translation forests](http://www.aclweb.org/anthology/D09-1005)

# Tips

* To construct an ITG use the template in section 1 of the project description and the lexicon of translation pairs that we provided.
* ITGs can be rather large and the resulting forests may be quite nasty to deal with, thus we recommend you constrain your ITG so that it contains only top-scoring translation pairs (you can use the IBM1 probabilities that we provided, you can choose one direction or interpolate both). For development we recommend you work with at most 5 translations per source word, once everything is working, you can investigate the impact of having more options.
* Note that your ITG has to be able to insert and delete words, thus it has to have translation pairs involving the empty string, for that you can use alignments to NULL in the lexicon we provided.
* You can pre-compute parse forests and feature functions and save them to disk (for example using `cPickle`), that should save some time during iterations of SGD.
