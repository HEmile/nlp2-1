
This project will help you familiarise yourself with word-based
models.  Word-based models remain at the core of today's SMT systems
in the form of alignment models.
You will implement the simplest (though still widely used) word-based
models, namely, IBM model 1, a lexical translation model, and IBM model 2, which models an impoverished form of word alignments.
% VB for Bayesian IBM1, cite Mermer+2011:BWA and Philip's notes?

In summary, your task is to

\begin{itemize}
	\item Implement IBM model 1;
	\item Implement IBM model 2 using a jump distribution as in \cite{Vogel+1996:HMMWA};
	\item Experiment with maximum likelihood estimation and variational Bayes;
	\item Write a technical report where you present the models and an empirical comparison. Your report should also present learning curves
    where applicable along with a discussion explaining aspects such
    as non-convexity, stability and convergence.
\end{itemize}

\section{IBM model 1}

\begin{enumerate}
	\item Implement IBM model 1 and its EM training \citep{Brown+1993:smt};
	\item Plot the evolution of the log likelihood function as a function of the iteration;
	\item Plot the evolution of alignment error rate (AER) on validation data as a function of the iteration;
	\item Experiment with two criteria for model selection (i.e. deciding on number of training iterations): 1) convergence in terms of log likelihood; 2) best AER on validation data;
	\item For the selected modes, obtain Viterbi alignments for every sentence pair in a test corpus and compute AER using a gold-standard provided by the assistant;
\end{enumerate}

%In your report, you should also consider the limitations of Model 1
%as described by \cite{Moore:2004:IBM1}, and find examples in your
%output to illustrate these limitations.

\section{IBM model 2}

\begin{enumerate}
  \item Extend your previous model by implementing a full IBM model 2 \citep{Brown+1993:smt}, however using the cheaper parameterisation in terms of jumps;
  \item IBM 2 is non-convex, thus you will see that optimising the log-likelihood function is 
        not as trivial as in the case of IBM model 1, particularly, convergence will depend 
        on how you initialise the model parameters, you will try
  \begin{itemize}
    \item uniform initialisation
    \item random initialisation (try 3 different starting points)
    \item initialise the lexical parameters using the output of a complete run of model 1
  \end{itemize}
  \item Plot the log-likelihood function as a function of the iteration for all these cases
  \item Plot validation AER as a function of the iteration for all these cases
  \item Select two models: 1) one in terms of log likelihood, 2) another in terms of validation AER;
  \item Compare the selected models to IBM model 1 in terms of AER in the test set.
\end{enumerate}

\section{Data}
You will be provided with parallel data taken from the Canadian Hansards (parliament proceedings). 
The data consists
of preprocessed sentence pairs (please do not further pre-process the data). There are two files, one for the
English and one for the French sentences. Sentences with the same line number are translations of each other.


\section{Report}

You should use latex for your report, here you will find a template: \url{http://acl2017.org/downloads/acl17-latex.zip} (unlike the template suggests, your submission should not be anonymous). 

We expect short reports (4 pages plus references) written in English covering at least the following:
\begin{itemize}
	\item abstract;
	\item introduction: discuss the problem and some background where relevant;
	\item model: technical description of models;
	\item experiments: details about the data, experimental setup and findings;
	\item conclusion.
\end{itemize}

